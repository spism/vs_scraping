# compose.yaml
services:
  scraper-worker:
    build:
      context: .
      dockerfile_inline: |
        FROM python:3.12-slim
        RUN apt-get update && apt-get install -y --no-install-recommends \
            build-essential gcc pkg-config \
            libxml2-dev libxslt1-dev libjpeg62-turbo-dev zlib1g-dev \
            libffi-dev ca-certificates curl \
          && rm -rf /var/lib/apt/lists/*
        WORKDIR /app
        RUN python -m pip install --upgrade pip wheel setuptools && \
            pip install --no-cache-dir \
              requests==2.32.3 beautifulsoup4==4.12.3 lxml==5.2.1 Pillow==10.4.0 \
              newspaper3k==0.2.8 trafilatura==1.8.1
        COPY . .
        CMD ["python", "worker.py"]

    container_name: scraper-worker
    environment:
      # You can override these at runtime if you want:
      # BACKEND_POST_URL: "https://your-backend.example.com/api/ingest"
      # BACKEND_TIMEOUT: "15"
      # BACKEND_MAX_ATTEMPTS: "3"
      # BACKEND_BACKOFF_SECONDS: "2"
      # ALLOW_OVERLAP: "false"
      # LOG_LEVEL: "INFO"
      SCRAPE_INTERVAL_SECONDS: "900"
      RUN_AT_START: "true"
    volumes:
      - .:/app                   # so you can iterate on code without rebuilds
    restart: always
